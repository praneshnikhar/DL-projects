{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4dM+lmT9IBBIxI1uICj1d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praneshnikhar/DL-projects/blob/main/MAE_on_satellite_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "jQ6qUfwivwrj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6u_zDunMvti6"
      },
      "outputs": [],
      "source": [
        "class PatchEmbed(nn.Module):\n",
        "    def __init__(self, img_size=128, patch_size=16, in_chans=3, embed_dim=768):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = (img_size // patch_size) ** 2\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x)  # [B, embed_dim, H', W']\n",
        "        x = x.flatten(2).transpose(1, 2)  # [B, num_patches, embed_dim]\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MAE(nn.Module):\n",
        "    def __init__(self, img_size=128, patch_size=16, in_chans=3, embed_dim=768, mask_ratio=0.75):\n",
        "        super().__init__()\n",
        "        self.patch_embed = PatchEmbed(img_size, patch_size, in_chans, embed_dim)\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(embed_dim, nhead=8), num_layers=6)\n",
        "        self.decoder = nn.TransformerDecoder(\n",
        "            nn.TransformerDecoderLayer(embed_dim, nhead=8), num_layers=4)\n",
        "        self.mask_ratio = mask_ratio\n",
        "        self.decoder_pred = nn.Linear(embed_dim, patch_size * patch_size * in_chans)\n",
        "\n",
        "    def random_masking(self, x):\n",
        "        N, L, D = x.shape\n",
        "        len_keep = int(L * (1 - self.mask_ratio))\n",
        "        noise = torch.rand(N, L, device=x.device)\n",
        "        ids_shuffle = torch.argsort(noise, dim=1)\n",
        "        ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
        "        ids_keep = ids_shuffle[:, :len_keep]\n",
        "        x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
        "        return x_masked, ids_restore, ids_keep\n",
        "\n",
        "    def forward(self, x):\n",
        "        patches = self.patch_embed(x)  # [B, num_patches, embed_dim]\n",
        "        x_masked, ids_restore, ids_keep = self.random_masking(patches)\n",
        "        enc_out = self.encoder(x_masked)\n",
        "        mask_tokens = torch.zeros(x.size(0), patches.size(1) - x_masked.size(1), enc_out.size(2), device=x.device)\n",
        "        dec_input = torch.cat([enc_out, mask_tokens], dim=1)\n",
        "        dec_input = torch.gather(dec_input, dim=1, index=ids_restore.unsqueeze(-1).repeat(1, 1, enc_out.size(2)))\n",
        "        dec_out = self.decoder(dec_input, enc_out)\n",
        "        pred = self.decoder_pred(dec_out)\n",
        "        return pred, patches\n"
      ],
      "metadata": {
        "id": "s-3FoqUHv0Y6"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}