# -*- coding: utf-8 -*-
"""Gradio GPT-2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f8Y4H3ccsVz9intEtFrl34HozLUavMYB
"""

!pip install -q gradio
!pip install -q git+https://github.com/huggingface/transformers.git

import gradio as gr
import tensorflow as tf
from transformers import TFGPT2LMHeadModel , GPT2Tokenizer

tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
model = TFGPT2LMHeadModel.from_pretrained("gpt2",pad_token_id=tokenizer.eos_token_id)

def generate_text(inp):
  input_ids = tokenizer.encode(inp, return_tensors = 'tf')
  beam_output = model.generate(input_ids, max_length = 100, num_beams = 5, no_repeat_ngram_size = 2, early_stopping = True)
  output = tokenizer.decode(beam_output[0], skip_special_tokens = True, clean_up_tokenization_spaces = True)
  return ".".join(output.split(".")[:-1]) + "."

output_text = gr.Textbox()

gr.Interface(
    fn=generate_text,
    inputs=gr.Textbox(placeholder="Enter a sentence..."),
    outputs=output_text,
    title="GPT-2",
    description="OpenAI's GPT-2 is an unsupervised language model that can generate coherent text. Input a sentence and see how it completes it!"
).launch()

